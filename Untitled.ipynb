{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import SentimentData\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentimentData=SentimentData.SentimentDataObject()\n",
    "\n",
    "INPUT_VECTOR_SIZE=sentimentData.X_train.shape[1]\n",
    "HIDDEN_LAYER1_SIZE=1024\n",
    "HIDDEN_LAYER2_SIZE=512\n",
    "OUTPUT_SIZE=sentimentData.y_train.shape[1]\n",
    "LEARNING_RATE=0.001\n",
    "NUM_EPOCHS=5\n",
    "BATCH_SIZE=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def truncated_normal_var(name, shape, dtype):\n",
    "    return (tf.get_variable(name=name, shape=shape, dtype=dtype, initializer=tf.truncated_normal_initializer(stddev=0.05)))\n",
    "\n",
    "def zero_var(name, shape, dtype):\n",
    "    return (tf.get_variable(name=name, shape=shape, dtype=dtype, initializer=tf.constant_initializer(0.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-ef553f293845>:21: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "validation_accuracy => [0.5241574]\n",
      "validation_accuracy => [0.5508138]\n",
      "validation_accuracy => [0.55350506]\n",
      "validation_accuracy => [0.56612843]\n",
      "validation_accuracy => [0.5673459]\n",
      "Final validation_accuracy => [0.5673459]\n"
     ]
    }
   ],
   "source": [
    "X=tf.placeholder(tf.float32,shape=[None,INPUT_VECTOR_SIZE],name='X')\n",
    "labels=tf.placeholder(tf.float32,shape=[None,OUTPUT_SIZE],name='labels')\n",
    "\n",
    "with tf.variable_scope('hidden_layer1') as scope:\n",
    "    hidden_weight1=truncated_normal_var(name='hidden_weight1',shape=[INPUT_VECTOR_SIZE,HIDDEN_LAYER1_SIZE],dtype=tf.float32)\n",
    "    hidden_bias1=zero_var(name='hidden_bias1',shape=[HIDDEN_LAYER1_SIZE],dtype=tf.float32)\n",
    "    hidden_layer1=tf.nn.relu(tf.matmul(X,hidden_weight1)+hidden_bias1)\n",
    "\n",
    "with tf.variable_scope('hidden_layer2') as scope:\n",
    "    hidden_weight2=truncated_normal_var(name='hidden_weight2',shape=[HIDDEN_LAYER1_SIZE,HIDDEN_LAYER2_SIZE],dtype=tf.float32)\n",
    "    hidden_bias2=zero_var(name='hidden_bias2',shape=[HIDDEN_LAYER2_SIZE],dtype=tf.float32)\n",
    "    hidden_layer2=tf.nn.relu(tf.matmul(hidden_layer1,hidden_weight2)+hidden_bias2)\n",
    "\n",
    "with tf.variable_scope('full_layer') as scope:\n",
    "    full_weight1=truncated_normal_var(name='full_weight1',shape=[HIDDEN_LAYER2_SIZE,OUTPUT_SIZE],dtype=tf.float32)\n",
    "    full_bias2 = zero_var(name='full_bias2', shape=[OUTPUT_SIZE], dtype=tf.float32)\n",
    "    final_output=tf.matmul(hidden_layer2,full_weight1)+full_bias2\n",
    "\n",
    "logits=tf.identity(final_output,name=\"logits\")\n",
    "\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=labels))\n",
    "train_step=tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(cost)\n",
    "correct_prediction=tf.equal(tf.argmax(final_output,1),tf.argmax(labels,1),name='correct_prediction')\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32),name='accuracy')\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "test_data_feed = {\n",
    "    X: sentimentData.X_cv,\n",
    "    labels: sentimentData.y_cv,\n",
    "}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch_X, batch_y in sentimentData.generate_one_epoch_for_neural(BATCH_SIZE):\n",
    "        train_data_feed = {\n",
    "            X: batch_X,\n",
    "            labels: batch_y,\n",
    "        }\n",
    "        sess.run(train_step, feed_dict={X:batch_X,labels:batch_y,})\n",
    "    validation_accuracy=sess.run([accuracy], test_data_feed)\n",
    "    print('validation_accuracy => '+str(validation_accuracy))\n",
    "\n",
    "validation_accuracy=sess.run([accuracy], test_data_feed)\n",
    "print('Final validation_accuracy => ' +str(validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PhraseId  SentenceId                                             Phrase  \\\n",
      "0    156061        8545  An intermittently pleasing but mostly routine ...   \n",
      "1    156062        8545  An intermittently pleasing but mostly routine ...   \n",
      "2    156063        8545                                                 An   \n",
      "3    156064        8545  intermittently pleasing but mostly routine effort   \n",
      "4    156065        8545         intermittently pleasing but mostly routine   \n",
      "\n",
      "                                   Vectorized_review  Classification  \n",
      "0  [0.3743246525049642, -0.3542049399294296, -0.3...               1  \n",
      "1  [0.3743246525049642, -0.3542049399294296, -0.3...               1  \n",
      "2  [0.36139386061393863, 0.5860913908609139, -0.2...               2  \n",
      "3  [0.37647372543790936, -0.51092815119748, -0.38...               1  \n",
      "4  [0.3099658006839863, -0.4913921721565569, -0.5...               1  \n",
      "   PhraseId  SentenceId                                             Phrase  \\\n",
      "0    156061        8545  An intermittently pleasing but mostly routine ...   \n",
      "1    156062        8545  An intermittently pleasing but mostly routine ...   \n",
      "2    156063        8545                                                 An   \n",
      "3    156064        8545  intermittently pleasing but mostly routine effort   \n",
      "4    156065        8545         intermittently pleasing but mostly routine   \n",
      "\n",
      "                                   Vectorized_review  Classification  \\\n",
      "0  [0.3743246525049642, -0.3542049399294296, -0.3...               1   \n",
      "1  [0.3743246525049642, -0.3542049399294296, -0.3...               1   \n",
      "2  [0.36139386061393863, 0.5860913908609139, -0.2...               2   \n",
      "3  [0.37647372543790936, -0.51092815119748, -0.38...               1   \n",
      "4  [0.3099658006839863, -0.4913921721565569, -0.5...               1   \n",
      "\n",
      "   Sentiment  \n",
      "0          1  \n",
      "1          1  \n",
      "2          2  \n",
      "3          1  \n",
      "4          1  \n"
     ]
    }
   ],
   "source": [
    "num_batches=int(sentimentData.test_data.shape[0])//BATCH_SIZE\n",
    "if BATCH_SIZE*num_batches<sentimentData.test_data.shape[0]:\n",
    "    num_batches+=1\n",
    "output=[]\n",
    "for j in range(num_batches):\n",
    "    batch_X=sentimentData.test_data[j*BATCH_SIZE:(j + 1)*BATCH_SIZE]\n",
    "    test_output=sess.run(tf.argmax(final_output,1),feed_dict={X:batch_X})\n",
    "    output.extend(test_output.tolist())\n",
    "    #print(len(output))\n",
    "\n",
    "\n",
    "sentimentData.df_test_input['Classification']=pd.Series(output)\n",
    "print(sentimentData.df_test_input.head())\n",
    "#sentimentData.df_test_input['Sentiment']=sentimentData.df_test_input['Classification'].apply(lambda x:sentimentData.lb.inverse_transform(x))\n",
    "sentimentData.df_test_input['Sentiment']=sentimentData.df_test_input['Classification'].apply(lambda x:x)\n",
    "print(sentimentData.df_test_input.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=sentimentData.df_test_input[['PhraseId','Sentiment']]\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_X=sentimentData.test_data[0:10]\n",
    "test_output=sess.run(tf.argmax(final_output,1),feed_dict={X:batch_X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1, 1, 3, 3, 2, 3, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(sentimentData.df_train_input['Sentiment'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
